{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from modules.MNIST import MNIST\n",
    "from modules.trainer import train_and_test, test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = MNIST(\"../MNIST_DATASET\")\n",
    "\n",
    "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
    "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
    "test_images = torch.tensor(test_images, dtype=torch.float32)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Add channel dimension (1 for grayscale images)\n",
    "train_images = train_images.unsqueeze(1)  # Shape: [N, 1, 28, 28]\n",
    "val_images = val_images.unsqueeze(1)      # Shape: [N, 1, 28, 28]\n",
    "test_images = test_images.unsqueeze(1)    # Shape: [N, 1, 28, 28]\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_images, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, stride=2, padding=1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "    self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "    self.conv4 = nn.Conv2d(64, 32, 5, 1)\n",
    "    self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x = F.relu(self.conv4(x))\n",
    "    x = x.view(-1, 32*1*1)\n",
    "    x = self.fc1(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "  num_elements = 0\n",
    "  for param in model.parameters():\n",
    "    num_elements += param.numel()\n",
    "  return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB \n",
    "GiB = 1024 * MiB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "train_and_test(model, train_loader, test_loader, optimizer, device, epochs)\n",
    "\n",
    "fp32_model_accuracy = test(model, device, test_loader)\n",
    "\n",
    "model_backup = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizer for 1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from fast_pytorch_kmeans import KMeans\n",
    "\n",
    "Codebook = namedtuple('Codebook', ['centroids', 'labels'])\n",
    "\n",
    "def k_means_quantize(fp32_tensor: torch.Tensor, bitwidth=4, codebook=None):\n",
    "  if codebook is None:\n",
    "    n_clusters = 2 ** bitwidth\n",
    "    kmeans = KMeans(n_clusters=n_clusters, mode='euclidean', verbose=False)\n",
    "    labels = kmeans.fit_predict(fp32_tensor.view(-1, 1)).to(torch.long)\n",
    "    centroids = kmeans.centroids.to(torch.float).view(-1)\n",
    "    codebook = Codebook(centroids, labels)\n",
    "\n",
    "  quantized_tensor = codebook.centroids[codebook.labels].view(fp32_tensor.shape)\n",
    "  fp32_tensor.set_(quantized_tensor.view_as(fp32_tensor))\n",
    "  return codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full model quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import parameter\n",
    "class KMeansQuantizer:\n",
    "    def __init__(self, model : nn.Module, bitwidth=4):\n",
    "        self.codebook = KMeansQuantizer.quantize(model, bitwidth)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply(self, model, update_centroids):\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in self.codebook:\n",
    "                if update_centroids:\n",
    "                    update_codebook(param, codebook=self.codebook[name]) # Defined below\n",
    "                self.codebook[name] = k_means_quantize(param, codebook=self.codebook[name])\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def quantize(model: nn.Module, bitwidth=4):\n",
    "        codebook = dict()\n",
    "        if isinstance(bitwidth, dict):\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in bitwidth:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth[name])\n",
    "        else:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth)\n",
    "        return codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing accuracy loss upon quantizing\n",
    "quantizers = dict()\n",
    "\n",
    "for bitwidth in [8, 4, 2]:\n",
    "    model = deepcopy(model_backup)\n",
    "    print(f'k-means quantizing model into {bitwidth} bits')\n",
    "    quantizer = KMeansQuantizer(model, bitwidth)\n",
    "    quantized_model_size = get_model_size(model, bitwidth)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "    quantized_model_accuracy = test(model, device, test_loader)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
    "    quantizers[bitwidth] = quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization aware training...\n",
    "# updated centroid = mean of weights in same cluster\n",
    "\n",
    "def update_codebook(fp32_tensor: torch.Tensor, codebook: Codebook):\n",
    "  n_clusters = codebook.centroids.numel()\n",
    "  fp32_tensor = fp32_tensor.view(-1)\n",
    "  for k in range(n_clusters):\n",
    "    codebook.centroids[k] = fp32_tensor[codebook.labels == k].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will only train if the accuracy diff is more than a certain threshold..\n",
    "accuracy_drop_threshold = 0.5\n",
    "quantizers_before_finetune = deepcopy(quantizers)\n",
    "quantizers_after_finetune = quantizers\n",
    "\n",
    "for bitwidth in [8, 4, 2]:\n",
    "  model = deepcopy(model_backup)\n",
    "  quantizer = quantizers[bitwidth]\n",
    "  print(f'k-means quantizing model into {bitwidth} bits')\n",
    "  quantizer.apply(model, update_centroids=False)\n",
    "  quantized_model_size = get_model_size(model, bitwidth)\n",
    "  print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "  quantized_model_accuracy = test(model, device, test_loader)\n",
    "  print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}% before quantization-aware training \")\n",
    "  accuracy_drop = fp32_model_accuracy - quantized_model_accuracy\n",
    "  \n",
    "  if accuracy_drop > accuracy_drop_threshold:\n",
    "    print(f\"        Quantization-aware training due to accuracy drop={accuracy_drop:.2f}% is larger than threshold={accuracy_drop_threshold:.2f}%\")\n",
    "    num_finetune_epochs = 5\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    best_accuracy = 0\n",
    "    epoch = num_finetune_epochs\n",
    "    while accuracy_drop > accuracy_drop_threshold and epoch > 0:\n",
    "      train(model, device, train_loader, optimizer, epoch,\n",
    "            callbacks=[lambda: quantizer.apply(model, update_centroids=True)])\n",
    "      model_accuracy = test(model, device, test_loader)\n",
    "      best_accuracy = max(model_accuracy, best_accuracy)\n",
    "      print(f'        Epoch {num_finetune_epochs-epoch} Accuracy {model_accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "      accuracy_drop = fp32_model_accuracy - best_accuracy\n",
    "      epoch -= 1\n",
    "  \n",
    "  else:\n",
    "    print(f\"        No need for quantization-aware training since accuracy drop={accuracy_drop:.2f}% is smaller than threshold={accuracy_drop_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])\n",
    "\n",
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8):\n",
    "  # Calc Scale and zero point of next\n",
    "  qmin = 0.\n",
    "  qmax = 2.**num_bits - 1.\n",
    "\n",
    "  scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "  initial_zero_point = qmin - min_val / scale\n",
    "\n",
    "  zero_point = 0\n",
    "  if initial_zero_point < qmin:\n",
    "      zero_point = qmin\n",
    "  elif initial_zero_point > qmax:\n",
    "      zero_point = qmax\n",
    "  else:\n",
    "      zero_point = initial_zero_point\n",
    "\n",
    "  zero_point = int(zero_point)\n",
    "\n",
    "  return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, num_bits=8, min_val=None, max_val=None):\n",
    "    if not min_val and not max_val:\n",
    "      min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    q_x = q_x.round().byte()\n",
    "\n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayer(x, layer, stat, scale_x, zp_x):\n",
    "  # for both conv and linear layers\n",
    "\n",
    "  # cache old values\n",
    "  W = layer.weight.data\n",
    "  B = layer.bias.data\n",
    "\n",
    "  # quantise weights, activations are already quantised\n",
    "  w = quantize_tensor(layer.weight.data)\n",
    "  b = quantize_tensor(layer.bias.data)\n",
    "\n",
    "  layer.weight.data = w.tensor.float()\n",
    "  layer.bias.data = b.tensor.float()\n",
    "\n",
    "  # This is Quantisation Artihmetic\n",
    "  scale_w = w.scale\n",
    "  zp_w = w.zero_point\n",
    "  scale_b = b.scale\n",
    "  zp_b = b.zero_point\n",
    "\n",
    "  scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "  # Preparing input by shifting\n",
    "  X = x.float() - zp_x\n",
    "  layer.weight.data = scale_x * scale_w*(layer.weight.data - zp_w)\n",
    "  layer.bias.data = scale_b*(layer.bias.data + zp_b)\n",
    "\n",
    "  # All int computation\n",
    "  x = (layer(X)/ scale_next) + zero_point_next\n",
    "\n",
    "  # Perform relu too\n",
    "  x = F.relu(x)\n",
    "\n",
    "  # Reset weights for next forward pass\n",
    "  layer.weight.data = W\n",
    "  layer.bias.data = B\n",
    "\n",
    "  return x, scale_next, zero_point_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now get max and min stats for quantising activations of network by running the network with around 1000 examples and getting the average min and max activation values before and after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Min and max of x tensor, and stores it\n",
    "def updateStats(x, stats, key):\n",
    "  max_val, _ = torch.max(x, dim=1)\n",
    "  min_val, _ = torch.min(x, dim=1)\n",
    "\n",
    "\n",
    "  if key not in stats:\n",
    "    stats[key] = {\"max\": max_val.sum(), \"min\": min_val.sum(), \"total\": 1}\n",
    "  else:\n",
    "    stats[key]['max'] += max_val.sum().item()\n",
    "    stats[key]['min'] += min_val.sum().item()\n",
    "    stats[key]['total'] += 1\n",
    "\n",
    "  return stats\n",
    "\n",
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1')\n",
    "\n",
    "  x = F.relu(model.conv1(x))\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n",
    "\n",
    "  x = F.relu(model.conv2(x))\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv3')\n",
    "\n",
    "  x = F.relu(model.conv3(x))\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv4')\n",
    "\n",
    "  x = F.relu(model.conv4(x))\n",
    "\n",
    "  x = x.view(-1, 32*1*1)\n",
    "\n",
    "  stats = updateStats(x, stats, 'fc1')\n",
    "\n",
    "  x = model.fc1(x)\n",
    "\n",
    "  return stats\n",
    "\n",
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, test_loader):\n",
    "    device = 'cuda'\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    stats = {}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            stats = gatherActivationStats(model, data, stats)\n",
    "\n",
    "    final_stats = {}\n",
    "    for key, value in stats.items():\n",
    "      final_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"] }\n",
    "    return final_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass for Quantised Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(model, x, stats):\n",
    "\n",
    "  # Quantise before inputting into incoming layers\n",
    "  x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'])\n",
    "\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point)\n",
    "\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['conv3'], scale_next, zero_point_next)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.conv3, stats['conv4'], scale_next, zero_point_next)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.conv4, stats['fc1'], scale_next, zero_point_next)\n",
    "\n",
    "  x = x.view(-1, 32*1*1)\n",
    "\n",
    "  # Back to dequant for final layer\n",
    "  x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "\n",
    "  x = model.fc1(x)\n",
    "\n",
    "  return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Function for Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, quant=False, stats=None):\n",
    "    device = 'cuda'\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if quant:\n",
    "              output = quantForward(model, data, stats)\n",
    "            else:\n",
    "              output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Accuracy of Quantised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = deepcopy(model_backup)\n",
    "stats = gatherStats(q_model, test_loader)\n",
    "print(stats)\n",
    "testQuant(q_model, test_loader, quant=True, stats=stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff_ml_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
