{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "from jax import numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "from modules.MNIST import MNIST\n",
    "from modules.trainer import TrainerModule\n",
    "from modules.pruner import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = MNIST(\"../MNIST_DATASET\")\n",
    "\n",
    "# Add channel dimension (1 for grayscale images)\n",
    "test_images  = jnp.expand_dims(test_images, axis=-1)\n",
    "val_images   = jnp.expand_dims(val_images, axis=-1)\n",
    "train_images = jnp.expand_dims(train_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = nn.initializers.xavier_normal\n",
    "class CNN(nn.Module):\n",
    "  # We will have to change these during channel pruning\n",
    "  out_channels: dict\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features= self.out_channels['Conv_0'], kernel_size=(3, 3), kernel_init= init())(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape= (2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=self.out_channels['Conv_1'], kernel_size=(3, 3), kernel_init= init())(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2,2))\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "    x = nn.Dense(features=256, kernel_init= init())(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=10, kernel_init= init())(x)\n",
    "    return x\n",
    "\n",
    "org_tm_cnn = TrainerModule(CNN, {'out_channels': {'Conv_0': 32, 'Conv_1': 64}}, \"adam\", 1e-3, jnp.ones((10, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = org_tm_cnn.train(train_data= (train_images, train_labels), val_data= (val_images, val_labels), num_epochs= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model_acc = org_tm_cnn.test(test_data= (test_images, test_labels))\n",
    "dense_model_size = org_tm_cnn.get_model_size()\n",
    "print(f\"Dense model accuracy: {dense_model_acc*100:.2f}%\")\n",
    "print(f\"Dense model size: {dense_model_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of weight values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_wt_dist_fig = org_tm_cnn.plot_weight_distribution()\n",
    "org_wt_dist_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine grained pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of org model\n",
    "fp_tm_cnn = deepcopy(org_tm_cnn)\n",
    "\n",
    "accuracies, sparsities = sensitivity_scan(fp_tm_cnn, test_data= (test_images, test_labels), verbose= False)\n",
    "plot_sensitivity_scan(sparsities, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of parameters in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Grained Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_dict = {\n",
    "  'Conv_0': 0.6,\n",
    "  'Conv_1': 0.7,\n",
    "  'Dense_0': 0.9,\n",
    "  'Dense_1': 0.8,\n",
    "}\n",
    "\n",
    "fgpruner = FineGrainedPruner(fp_tm_cnn, sparsity_dict)\n",
    "\n",
    "fgpruner.apply()\n",
    "print(f\"Model sparsity before pruning: {org_tm_cnn.get_model_sparsity()}\")\n",
    "print(f\"Model size before pruning: {org_tm_cnn.get_model_size()}\")\n",
    "print(f\"Model accuracy before pruning: {org_tm_cnn.test(test_data= (test_images, test_labels))}\")\n",
    "\n",
    "print(f\"Model sparsity after pruning: {fp_tm_cnn.get_model_sparsity()}\")\n",
    "print(f\"Model size after pruning: {fp_tm_cnn.get_model_size()}\")\n",
    "print(f\"Model accuracy after pruning: {fp_tm_cnn.test(test_data= (test_images, test_labels))}\")\n",
    "\n",
    "wt_dist_fp_fig = fp_tm_cnn.plot_weight_distribution(count_nonzero_only=True)\n",
    "wt_dist_fp_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = fp_tm_cnn.train(train_data= (train_images, train_labels), val_data= (val_images, val_labels), num_epochs= 5, callbacks= [fgpruner.apply], verbose = False)\n",
    "\n",
    "print(f\"Pruned model sparsity after finetuning: {fp_tm_cnn.get_model_sparsity()}\")\n",
    "print(f\"Pruned model size after finetuning: {fp_tm_cnn.get_model_size()}\")\n",
    "print(f\"Pruned model accuracy after finetuning: {fp_tm_cnn.test(test_data= (test_images, test_labels))}\")\n",
    "fp_tm_cnn.plot_weight_distribution(count_nonzero_only=True)\n",
    "\n",
    "fig = None\n",
    "fig = fp_tm_cnn.plot_num_parameters(count_nonzero_only= True, color='red', fig= fig)\n",
    "fig = org_tm_cnn.plot_num_parameters(count_nonzero_only= True, color='blue', fig= fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of org model for channel pruning\n",
    "cp_tm_cnn = deepcopy(org_tm_cnn)\n",
    "\n",
    "cpruner = ChannelPruner(cp_tm_cnn)\n",
    "cpruner.apply(prune_ratio = 0.8)\n",
    "\n",
    "cp_tm_cnn.init_train_state(cp_tm_cnn.model.apply, cp_tm_cnn.state.params, cp_tm_cnn.tx)\n",
    "print(f\"Pruned model size: {cp_tm_cnn.get_model_size()}\")\n",
    "print(f\"Pruned model accuracy: {cp_tm_cnn.test(test_data= (test_images, test_labels))}\")\n",
    "\n",
    "best_state = cp_tm_cnn.train(train_data= (train_images, train_labels), val_data= (val_images, val_labels), num_epochs= 5, verbose= False)\n",
    "print(f\"Pruned model size after finetuning: {cp_tm_cnn.get_model_size()}\")\n",
    "print(f\"Pruned model accuracy after finetuning: {cp_tm_cnn.test(test_data= (test_images, test_labels))}\")\n",
    "\n",
    "fig = None\n",
    "fig = cp_tm_cnn.plot_num_parameters(count_nonzero_only= True, color='red', fig= fig)\n",
    "fig = org_tm_cnn.plot_num_parameters(count_nonzero_only= True, color='blue', fig= fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency(tm_cnn: TrainerModule, dummy_inp, n_warmup= 20, n_test = 1000):\n",
    "  for _ in range(n_warmup):\n",
    "    tm_cnn.test(dummy_inp)\n",
    "  \n",
    "  st = time.perf_counter()\n",
    "  for _ in range(n_test):\n",
    "    tm_cnn.test(dummy_inp)\n",
    "  end = time.perf_counter()\n",
    "\n",
    "  rt_us = ( ((end - st) / n_test) / len(dummy_inp[1]) ) * 1e6\n",
    "  return rt_us\n",
    "\n",
    "print(f\"Org Model            | Size: {org_tm_cnn.get_model_size()}   | Acc: {org_tm_cnn.test(test_data= (test_images, test_labels)):.3f} | Latency: {measure_latency(org_tm_cnn, (test_images, test_labels)):.2f} us\")\n",
    "print(f\"Channel Pruned Model | Size: {cp_tm_cnn.get_model_size()} | Acc: {cp_tm_cnn.test(test_data= (test_images, test_labels)):.3f} | Latency: {measure_latency(cp_tm_cnn, (test_images, test_labels)):.2f} us\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
